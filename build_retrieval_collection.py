#!/usr/bin/env python3
"""
åŸºäºOpenClawæ–‡æ¡£å’ŒæŠ€èƒ½çš„æ£€ç´¢é›†åˆæ„å»ºå·¥å…·
ä½¿ç”¨qmdæŠ€èƒ½åŠ é€Ÿæ£€ç´¢æ•ˆç‡
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Any
import hashlib

class RetrievalCollectionBuilder:
    def __init__(self, workspace_path: str = "/root/.openclaw/workspace"):
        self.workspace_path = Path(workspace_path)
        self.collection_config = {}
        self.retrieval_index = {}
        self.search_cache = {}

    def load_collection_config(self, config_path: str = "collections/openclaw-docs-skills.json"):
        """åŠ è½½collectioné…ç½®æ–‡ä»¶"""
        config_file = self.workspace_path / config_path
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                self.collection_config = json.load(f)
            print(f"âœ… å·²åŠ è½½é…ç½®: {self.collection_config['name']}")
            return True
        else:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return False

    def extract_content(self, file_path: str) -> str:
        """æå–æ–‡ä»¶å†…å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content
        except Exception as e:
            print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return ""

    def create_search_index(self):
        """åˆ›å»ºæ£€ç´¢ç´¢å¼•"""
        print("ğŸ” å¼€å§‹åˆ›å»ºæ£€ç´¢ç´¢å¼•...")

        # ç´¢å¼•æ–‡æ¡£
        for doc in self.collection_config.get('documents', []):
            doc_path = self.workspace_path / doc['path']
            if doc_path.exists():
                content = self.extract_content(str(doc_path))
                if content:
                    # åˆ›å»ºå…³é”®è¯ç´¢å¼•
                    keywords = self.extract_keywords(content)
                    self.retrieval_index[f"doc:{doc['title']}"] = {
                        'type': 'document',
                        'title': doc['title'],
                        'path': doc['path'],
                        'keywords': keywords,
                        'content_hash': hashlib.md5(content.encode()).hexdigest()[:8],
                        'category': doc.get('category', 'unknown')
                    }

        # ç´¢å¼•æŠ€èƒ½
        for skill in self.collection_config.get('skills', []):
            skill_path = self.workspace_path / skill['path']
            if skill_path.exists():
                content = self.extract_content(str(skill_path))
                if content:
                    keywords = self.extract_keywords(content)
                    self.retrieval_index[f"skill:{skill['title']}"] = {
                        'type': 'skill',
                        'title': skill['title'],
                        'path': skill['path'],
                        'keywords': keywords,
                        'content_hash': hashlib.md5(content.encode()).hexdigest()[:8],
                        'category': skill.get('category', 'unknown')
                    }

        print(f"âœ… æ£€ç´¢ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…±ç´¢å¼• {len(self.retrieval_index)} ä¸ªé¡¹ç›®")

    def extract_keywords(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–å…³é”®è¯"""
        # ç§»é™¤ä»£ç å—å’Œç‰¹æ®Šå­—ç¬¦
        content = re.sub(r'```.*?```', '', content, flags=re.DOTALL)
        content = re.sub(r'`.*?`', '', content)
        content = re.sub(r'[^\w\s]', ' ', content)

        # æå–ä¸­æ–‡å…³é”®è¯
        chinese_words = re.findall(r'[\u4e00-\u9fff]+', content)
        # æå–è‹±æ–‡å…³é”®è¯
        english_words = re.findall(r'\b[a-zA-Z]{3,}\b', content)

        # è¿‡æ»¤å¸¸è§åœç”¨è¯
        stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'this', 'that', 'these', 'those', 'a', 'an'}

        keywords = []
        for word in chinese_words + english_words:
            word = word.lower().strip()
            if len(word) > 1 and word not in stop_words:
                keywords.append(word)

        return list(set(keywords))  # å»é‡

    def build_optimized_collection(self):
        """æ„å»ºä¼˜åŒ–çš„æ£€ç´¢é›†åˆ"""
        print("ğŸš€ å¼€å§‹æ„å»ºä¼˜åŒ–æ£€ç´¢é›†åˆ...")

        # åˆ›å»ºä¼˜åŒ–åçš„collectionæ–‡ä»¶
        optimized_collection = {
            'metadata': {
                'name': self.collection_config.get('name', 'OpenClawæ£€ç´¢é›†åˆ'),
                'version': '2.0.0',
                'created': '2026-02-08',
                'last_build': '2026-02-08T14:23:00Z',
                'total_items': len(self.retrieval_index),
                'optimized': True
            },
            'retrieval_index': self.retrieval_index,
            'search_tips': [
                "ä½¿ç”¨å…³é”®è¯æœç´¢: 'å¤©æ°”æŸ¥è¯¢', 'æ–‡ä»¶ç®¡ç†', 'è®¡ç®—å™¨'",
                "æœç´¢æŠ€èƒ½åŠŸèƒ½: 'weather', 'file', 'calculation'",
                "æœç´¢æ–‡æ¡£ç±»å‹: 'APIæ–‡æ¡£', 'æ¶æ„æ–‡æ¡£', 'CLIæ–‡æ¡£'"
            ],
            'quick_access': {
                'documents': [item['title'] for item in self.collection_config.get('documents', [])],
                'skills': [item['title'] for item in self.collection_config.get('skills', [])]
            }
        }

        # ä¿å­˜ä¼˜åŒ–åçš„é›†åˆ
        output_file = self.workspace_path / "collections/optimized_openclaw_collection.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(optimized_collection, f, ensure_ascii=False, indent=2)

        print(f"âœ… ä¼˜åŒ–æ£€ç´¢é›†åˆå·²ä¿å­˜åˆ°: {output_file}")
        print(f"ğŸ“Š é›†åˆåŒ…å« {len(self.retrieval_index)} ä¸ªæ£€ç´¢é¡¹ç›®")

        return output_file

    def generate_search_commands(self):
        """ç”Ÿæˆæœç´¢å‘½ä»¤ç¤ºä¾‹"""
        print("\nğŸ“ æœç´¢å‘½ä»¤ç¤ºä¾‹:")
        print("=" * 50)
        print("1. æœç´¢å…³é”®è¯:")
        print("   qmd search 'å¤©æ°”æŸ¥è¯¢'")
        print("   qmd search 'æ–‡ä»¶ç®¡ç†'")
        print("   qmd search 'APIæ–‡æ¡£'")
        print()
        print("2. æœç´¢ç‰¹å®šç±»å‹:")
        print("   qmd search --type document 'CLIæ–‡æ¡£'")
        print("   qmd search --type skill 'è®¡ç®—å™¨'")
        print()
        print("3. è·å–é›†åˆä¿¡æ¯:")
        print("   qmd collection info openclaw-docs-skills")
        print()
        print("4. åˆ—å‡ºæ‰€æœ‰æŠ€èƒ½:")
        print("   qmd list skills")
        print()
        print("5. åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£:")
        print("   qmd list documents")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ OpenClawæ–‡æ¡£ä¸æŠ€èƒ½æ£€ç´¢é›†åˆæ„å»ºå·¥å…·")
    print("=" * 50)

    builder = RetrievalCollectionBuilder()

    # åŠ è½½é…ç½®
    if not builder.load_collection_config():
        return

    # åˆ›å»ºæ£€ç´¢ç´¢å¼•
    builder.create_search_index()

    # æ„å»ºä¼˜åŒ–é›†åˆ
    output_file = builder.build_optimized_collection()

    # ç”Ÿæˆæœç´¢å‘½ä»¤
    builder.generate_search_commands()

    print(f"\nğŸ‰ æ£€ç´¢é›†åˆæ„å»ºå®Œæˆï¼")
    print(f"ğŸ“ é›†åˆæ–‡ä»¶: {output_file}")
    print(f"ğŸ” ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨qmdå·¥å…·å¿«é€Ÿæ£€ç´¢æ–‡æ¡£å’ŒæŠ€èƒ½äº†ï¼")

if __name__ == "__main__":
    main()