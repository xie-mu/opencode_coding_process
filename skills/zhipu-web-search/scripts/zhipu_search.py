#!/usr/bin/env python3
"""
æ™ºè°±AIç½‘ç»œæœç´¢APIè°ƒç”¨è„šæœ¬
é€šè¿‡ chat completions API è°ƒç”¨ web_search å·¥å…·
"""

import os
import sys
import json
import argparse
import requests
import re
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse


API_BASE_URL = "https://open.bigmodel.cn/api/paas/v4"


def search(
    search_query: str,
    search_engine: str = "search_std",
    search_intent: bool = False,
    count: int = 10,
    search_domain_filter: Optional[str] = None,
    search_recency_filter: Optional[str] = None,
    content_size: Optional[str] = None,
    request_id: Optional[str] = None,
    user_id: Optional[str] = None,
) -> Dict[str, Any]:
    """
    è°ƒç”¨æ™ºè°±æœç´¢API
    
    å‚æ•°ä¸æ™ºè°±APIä¿æŒä¸€è‡´ï¼Œæä¾›æœ€å¤§çš„çµæ´»æ€§
    """
    api_key = os.environ.get("ZHIPU_API_KEY")
    if not api_key:
        raise ValueError("ZHIPU_API_KEY environment variable is not set")
    
    # æ„å»ºå·¥å…·è°ƒç”¨å‚æ•°
    tool_params = {
        "search_query": search_query,
        "search_engine": search_engine,
        "search_intent": search_intent,
        "count": count,
    }
    
    # æ·»åŠ å¯é€‰å‚æ•°
    if search_domain_filter:
        tool_params["search_domain_filter"] = search_domain_filter
    if search_recency_filter:
        tool_params["search_recency_filter"] = search_recency_filter
    if content_size:
        tool_params["content_size"] = content_size
    
    # æ„å»ºè¯·æ±‚ä½“ - ä½¿ç”¨ function calling æ–¹å¼
    payload: Dict[str, Any] = {
        "model": "glm-4-flash",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿä½¿ç”¨æœç´¢å·¥å…·çš„AIåŠ©æ‰‹ã€‚å½“ç”¨æˆ·éœ€è¦æœç´¢ä¿¡æ¯æ—¶ï¼Œè¯·ä½¿ç”¨web_searchå·¥å…·ã€‚"},
            {"role": "user", "content": search_query}
        ],
        "tools": [
            {
                "type": "web_search",
                "web_search": {
                    "enable": True,
                    **tool_params
                }
            }
        ],
        "tool_choice": "auto",
    }
    
    # æ·»åŠ å¯é€‰çš„å…ƒæ•°æ®
    if request_id:
        payload["request_id"] = request_id
    if user_id:
        payload["user_id"] = user_id
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    
    response = requests.post(
        f"{API_BASE_URL}/chat/completions",
        headers=headers,
        json=payload,
        timeout=60,
    )
    
    response.raise_for_status()
    result = response.json()
    
    # æå–æœç´¢ç»“æœ
    return extract_search_results(result, search_query)


def extract_search_results(response: Dict[str, Any], original_query: str) -> Dict[str, Any]:
    """ä»APIå“åº”ä¸­æå–æœç´¢ç»“æœ"""
    output = {
        "id": response.get("id", ""),
        "created": response.get("created", 0),
        "request_id": response.get("request_id", ""),
        "search_query": original_query,
        "search_intent": [],
        "search_result": [],
        "raw_response": response,
    }
    
    # å°è¯•ä» choices ä¸­æå–å·¥å…·è°ƒç”¨ç»“æœ
    choices = response.get("choices", [])
    if not choices:
        return output
    
    message = choices[0].get("message", {})
    
    # æ£€æŸ¥ tool_calls (ç»“æ„åŒ–æœç´¢ç»“æœ)
    tool_calls = message.get("tool_calls", [])
    for tool_call in tool_calls:
        if tool_call.get("type") == "web_search":
            web_search_result = tool_call.get("web_search", {})
            if "search_intent" in web_search_result:
                output["search_intent"] = web_search_result["search_intent"]
            if "search_result" in web_search_result:
                output["search_result"] = web_search_result["search_result"]
    
    # å¦‚æœæ²¡æœ‰ç»“æ„åŒ–ç»“æœï¼Œå°è¯•ä» content ä¸­è§£æ
    content = message.get("content", "")
    if content and not output["search_result"]:
        # å°è¯•è§£æ JSON
        try:
            if isinstance(content, str) and content.strip().startswith("{"):
                parsed = json.loads(content)
                if "search_result" in parsed:
                    output["search_result"] = parsed["search_result"]
                elif "results" in parsed:
                    output["search_result"] = parsed["results"]
        except:
            pass
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–é“¾æ¥å’Œä¿¡æ¯
        if not output["search_result"]:
            parsed_results = parse_text_to_results(content)
            if parsed_results:
                output["search_result"] = parsed_results
    
    output["model_response"] = content
    return output


def parse_text_to_results(text: str) -> List[Dict[str, Any]]:
    """å°è¯•ä»æ–‡æœ¬å†…å®¹ä¸­æå–æœç´¢ç»“æœ"""
    results = []
    
    # åŒ¹é…URLæ¨¡å¼
    url_pattern = r'https?://[^\s\)\]\>\"\']+'
    urls = re.findall(url_pattern, text)
    
    # æŒ‰æ®µè½åˆ†å‰²
    paragraphs = text.split('\n\n')
    
    for i, para in enumerate(paragraphs):
        # æŸ¥æ‰¾åŒ…å«URLçš„æ®µè½
        para_urls = re.findall(url_pattern, para)
        if para_urls or (para.strip() and len(para) > 20):
            # å°è¯•æå–æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯æ¯”è¾ƒçŸ­çš„å¥å­æˆ–åŠ ç²—å†…å®¹ï¼‰
            lines = para.strip().split('\n')
            title = lines[0][:100] if lines else f"ç»“æœ {i+1}"
            
            # æ¸…ç†æ ‡é¢˜
            title = re.sub(r'^\d+\.\s*', '', title)
            title = re.sub(r'^[\*\-\#]+\s*', '', title)
            
            result = {
                "title": title,
                "content": para[:500],
                "link": para_urls[0] if para_urls else "",
                "media": extract_domain(para_urls[0]) if para_urls else "",
            }
            results.append(result)
    
    return results[:10]  # æœ€å¤šè¿”å›10æ¡


def extract_domain(url: str) -> str:
    """ä»URLä¸­æå–åŸŸå"""
    try:
        parsed = urlparse(url)
        return parsed.netloc.replace('www.', '')
    except:
        return ""


def format_results(data: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¯è¯»æ–‡æœ¬"""
    lines = []
    
    lines.append(f"ğŸ” æœç´¢: {data.get('search_query', 'N/A')}")
    lines.append("")
    
    # æœç´¢æ„å›¾ä¿¡æ¯
    if data.get("search_intent"):
        lines.append("=== æœç´¢æ„å›¾ ===")
        for intent in data["search_intent"]:
            lines.append(f"åŸå§‹Query: {intent.get('query', 'N/A')}")
            lines.append(f"è¯†åˆ«æ„å›¾: {intent.get('intent', 'N/A')}")
            lines.append(f"æ”¹å†™å…³é”®è¯: {intent.get('keywords', 'N/A')}")
        lines.append("")
    
    # æœç´¢ç»“æœ
    results = data.get("search_result", [])
    if results:
        lines.append(f"=== æœç´¢ç»“æœ (å…±{len(results)}æ¡) ===")
        for idx, result in enumerate(results, 1):
            lines.append(f"\n[{idx}] {result.get('title', 'æ— æ ‡é¢˜')}")
            if result.get('media'):
                lines.append(f"    æ¥æº: {result['media']}")
            if result.get('link'):
                lines.append(f"    é“¾æ¥: {result['link']}")
            if result.get('publish_date'):
                lines.append(f"    å‘å¸ƒæ—¶é—´: {result['publish_date']}")
            content = result.get('content', '')
            if content:
                lines.append(f"    æ‘˜è¦: {content[:200]}{'...' if len(content) > 200 else ''}")
    else:
        lines.append("æœªæ‰¾åˆ°ç»“æ„åŒ–æœç´¢ç»“æœ")
        # æ˜¾ç¤ºæ¨¡å‹å›å¤
        if data.get("model_response"):
            lines.append("\n=== æ¨¡å‹å›å¤ ===")
            lines.append(data["model_response"][:1000])
    
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="æ™ºè°±AIç½‘ç»œæœç´¢å·¥å…·")
    
    # å¿…å¡«å‚æ•°
    parser.add_argument(
        "--query", "-q",
        required=True,
        help="æœç´¢å†…å®¹ (search_query)ï¼Œå»ºè®®ä¸è¶…è¿‡70å­—ç¬¦"
    )
    parser.add_argument(
        "--engine", "-e",
        default="search_std",
        choices=["search_std", "search_pro", "search_pro_sogou", "search_pro_quark"],
        help="æœç´¢å¼•æ“ (search_engine)ï¼Œé»˜è®¤: search_std"
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--intent", "-i",
        action="store_true",
        help="å¯ç”¨æœç´¢æ„å›¾è¯†åˆ« (search_intent)"
    )
    parser.add_argument(
        "--count", "-c",
        type=int,
        default=10,
        help="è¿”å›ç»“æœæ•°é‡ (count)ï¼ŒèŒƒå›´1-50ï¼Œé»˜è®¤: 10"
    )
    parser.add_argument(
        "--domain-filter", "-d",
        help="åŸŸåç™½åå•è¿‡æ»¤ (search_domain_filter)"
    )
    parser.add_argument(
        "--recency", "-r",
        choices=["oneDay", "oneWeek", "oneMonth", "oneYear", "noLimit"],
        help="æ—¶é—´èŒƒå›´è¿‡æ»¤ (search_recency_filter)"
    )
    parser.add_argument(
        "--content-size", "-s",
        choices=["medium", "high"],
        help="å†…å®¹é•¿åº¦æ§åˆ¶ (content_size): medium(æ‘˜è¦) / high(è¯¦ç»†)"
    )
    parser.add_argument(
        "--request-id",
        help="å”¯ä¸€è¯·æ±‚æ ‡è¯† (request_id)"
    )
    parser.add_argument(
        "--user-id", "-u",
        help="ç»ˆç«¯ç”¨æˆ·ID (user_id)ï¼Œ6-128å­—ç¬¦"
    )
    parser.add_argument(
        "--json", "-j",
        action="store_true",
        help="è¾“å‡ºåŸå§‹JSONæ ¼å¼"
    )
    
    args = parser.parse_args()
    
    try:
        result = search(
            search_query=args.query,
            search_engine=args.engine,
            search_intent=args.intent,
            count=args.count,
            search_domain_filter=args.domain_filter,
            search_recency_filter=args.recency,
            content_size=args.content_size,
            request_id=args.request_id,
            user_id=args.user_id,
        )
        
        if args.json:
            # ç§»é™¤ raw_response ä»¥å‡å°‘è¾“å‡º
            output = {k: v for k, v in result.items() if k != "raw_response"}
            print(json.dumps(output, ensure_ascii=False, indent=2))
        else:
            print(format_results(result))
            
    except requests.exceptions.RequestException as e:
        print(f"APIè¯·æ±‚å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)
    except ValueError as e:
        print(f"é…ç½®é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
